{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sounddevice as SD\n",
    "from scipy.io import wavfile\n",
    "import scipy.fft as fft\n",
    "import matplotlib.pyplot as plt\n",
    "import numba as nb\n",
    "import os\n",
    "import functools\n",
    "import time\n",
    "import math\n",
    "def time_func(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        t0 = time.perf_counter()\n",
    "        value = func(*args, **kwargs)\n",
    "        t = time.perf_counter()-t0\n",
    "        print(func.__name__, t)\n",
    "        return value\n",
    "    return wrapper\n",
    "\n",
    "@nb.njit(['i2[:,:](i2[:],i4)','i4[:,:](i4[:],i4)', 'i8[:,:](i8[:],i8)'], parallel = True)\n",
    "def Chunking_Sample(sample, chunk_size):\n",
    "    ''' This is an optimised chunking algorithm to split\n",
    "     a sample into a 2D array of time slices\n",
    "    '''\n",
    "    result_type = sample.dtype\n",
    "    chunks = int(np.floor(sample.size/chunk_size))\n",
    "    result = np.zeros((chunks,chunk_size), dtype=result_type)\n",
    "    for chunk_num in nb.prange(chunks):\n",
    "        result[chunk_num] = sample[chunk_num*chunk_size : (chunk_num+1)*chunk_size]\n",
    "    return result\n",
    "@nb.njit(['i2[:,:,:](i2[:,:],i4)','i4[:,:,:](i4[:,:],i4)', 'i8[:,:,:](i8[:,:],i8)'], parallel = True)\n",
    "def Chunking_Sample_ARRAY(sample, chunk_size):\n",
    "    ''' This is an optimised chunking algorithm to split\n",
    "     a sample into a 2D array of time slices\n",
    "    '''\n",
    "    result_type = sample.dtype\n",
    "    chunks = int(np.floor(sample.shape[-1]/chunk_size))\n",
    "    result = np.zeros((sample.shape[0],chunks,chunk_size), dtype=result_type)\n",
    "    for i in nb.prange(sample.shape[0]):\n",
    "        for chunk_num in nb.prange(chunks):\n",
    "            result[i, chunk_num] = sample[i, chunk_num*chunk_size : (chunk_num+1)*chunk_size]\n",
    "    return result\n",
    "@nb.njit('f8[:,:](f8[:],i8, i2)', parallel = True)\n",
    "def Chunking_Multisample(data, chunksize, chunks):\n",
    "    start = np.random.choice(data.size-chunksize, size = chunks)\n",
    "    # take a slice of the data from the song\n",
    "    # data = data[start:start+int(rate*record_duration)]\n",
    "    result = np.zeros((chunks, chunksize), dtype = data.dtype)\n",
    "    for i in nb.prange(start.shape[0]):\n",
    "        result[i] = data[start[i]:start[i]+chunksize]\n",
    "    return result\n",
    "\n",
    "\n",
    "@nb.njit('Tuple((f8[:,:,:],f8[:,:]))(f8[:], c16[:,:,:],f8,i4)', parallel = True)\n",
    "def hashed_freqs_ARRAY(freqs, fourier, time_slices, octave_factor):\n",
    "    ''' Function to generate a set of times and the peaks of the fourier transform \n",
    "    for a sample of music'''\n",
    "    semitone_steps = int(12/octave_factor)\n",
    "    base_range = 5\n",
    "    range_lower = int(base_range*octave_factor)\n",
    "    range_upper = int(base_range*octave_factor) - (octave_factor-1)\n",
    "    semitones = np.array([i*semitone_steps for i in range(-range_lower,range_upper,1)], dtype=np.int32)\n",
    "    bin_edges = note_frequencies(semitones, 440)\n",
    "    bin_edges_reduced = [bin_edges[0]]\n",
    "    for i in range(len(bin_edges)-1):\n",
    "        if bin_edges[i+1] - bin_edges[i] > 12:\n",
    "            bin_edges_reduced.append(bin_edges[i+1])\n",
    "    bin_edges = bin_edges_reduced.copy()\n",
    "    bins = len(bin_edges)-1\n",
    "    peaks = np.empty((*fourier.shape[:-1],bins), dtype = np.float64)\n",
    "    times = np.empty(fourier.shape[:-1], dtype = np.float64)\n",
    "    # resolution gives the length of a section of each bin\n",
    "    abs_data = np.abs(fourier)\n",
    "    for test in nb.prange(fourier.shape[0]):\n",
    "        for time in nb.prange(fourier.shape[1]):\n",
    "            # iterates through each time slice of music\n",
    "            for bin in nb.prange(bins):\n",
    "                # works through each bin range to find the freq upper and lower limits\n",
    "                upper_lim = bin_edges[bin+1]\n",
    "                lower_lim = bin_edges[bin]\n",
    "                # finds the indices of the freqs where this occurs\n",
    "                indices = np.where((freqs <= upper_lim) & (freqs > lower_lim))[0]\n",
    "                # finds the peak in this range\n",
    "                peak = np.where(abs_data[test][time][indices]== np.max(abs_data[test][time][indices]))[0][0]\n",
    "                # appends the position of the peak within the overall data set to an array\n",
    "                peaks[test][time][bin] = freqs[np.int32(peak+indices[0])]\n",
    "            # calculates the time where this time slice occurred\n",
    "            times[test][time] = time*time_slices\n",
    "    return peaks, times\n",
    "\n",
    "@nb.njit(['f8[:](i4[:], i4)', 'f8(i4, i4)'])\n",
    "def note_frequencies(n, f0):\n",
    "    ''' This simply returns the frequencies of the notes along the equal temperament scale'''\n",
    "    ''' f0 -> fundamental frequency / Hz\n",
    "        n -> number of halfsteps from note'''\n",
    "    return f0 * np.power(2,n/12)\n",
    "\n",
    "@nb.njit('Tuple((i4[:,:],f8[:]))(f8[:], c16[:,:],f8,i4)', parallel = True)\n",
    "def hashed_freqs_nonuniform(freqs, fourier, time_slices, octave_factor):\n",
    "    ''' Function to generate a set of times and the peaks of the fourier transform \n",
    "    for a sample of music'''\n",
    "    semitone_steps = int(12/octave_factor)\n",
    "    base_range = 5\n",
    "    range_lower = int(base_range*octave_factor)\n",
    "    range_upper = int(base_range*octave_factor) - (octave_factor-1)\n",
    "    semitones = np.array([i*semitone_steps for i in range(-range_lower,range_upper,1)], dtype=np.int32)\n",
    "    bin_edges = note_frequencies(semitones, 440)\n",
    "    bin_edges_reduced = [bin_edges[0]]\n",
    "    for i in range(len(bin_edges)-1):\n",
    "        if bin_edges[i+1] - bin_edges[i] > 12:\n",
    "            bin_edges_reduced.append(bin_edges[i+1])\n",
    "    bin_edges = bin_edges_reduced.copy()\n",
    "    bins = len(bin_edges)-1\n",
    "    peaks = np.empty((fourier.shape[0],bins), dtype = np.int32)\n",
    "    times = np.empty(fourier.shape[0])\n",
    "    # resolution gives the length of a section of each bin\n",
    "    for time in nb.prange(fourier.shape[0]):\n",
    "        # iterates through each time slice of music\n",
    "        for bin_num in range(bins):\n",
    "            # works through each bin range to find the freq upper and lower limits\n",
    "            upper_lim = bin_edges[bin_num+1]\n",
    "            lower_lim = bin_edges[bin_num]\n",
    "            # finds the indices of the freqs where this occurs\n",
    "            indices = np.where((freqs <= upper_lim) & (freqs > lower_lim))[0]\n",
    "            # finds the peak in this range\n",
    "            peak = np.where(np.abs(fourier[time][indices]) == np.max(np.abs(fourier[time][indices])))[0][0]\n",
    "            # appends the position of the peak within the overall data set to an array\n",
    "            peaks[time][bin_num] = np.int32(peak+indices[0])\n",
    "        # calculates the time where this time slice occurred\n",
    "        times[time] = time*time_slices\n",
    "    # print(peaks)\n",
    "    return peaks, times\n",
    "\n",
    "def create_fingerprint_song(file_name: str,time_slice: float,octave_factor = 1):\n",
    "    '''This function takes a song that has been downloaded to the music file\n",
    "        Then generates the fingerprint of the song and saves the fingerprint data to a file'''\n",
    "    rate, data = wavfile.read('../Music/{}'.format(file_name)) # read in the wav file\n",
    "    data = np.sum(data,axis = -1, dtype = np.int32) # converts stereo to mono\n",
    "    fingerprints = Chunking_Sample(data,int(time_slice*rate)) # chunks the data\n",
    "    # calculate fourier data\n",
    "    Fourier_fingerprints = fft.rfft(fingerprints)\n",
    "    Freqs_fingerprints = fft.rfftfreq(fingerprints.shape[-1], 1/rate)\n",
    "    # finds the peaks\n",
    "    peaks, times = hashed_freqs_nonuniform(Freqs_fingerprints,Fourier_fingerprints,time_slice,octave_factor)\n",
    "    # rounds the times to the decimal places of the time slice (removes floating point error)\n",
    "    times = np.round(times, int(np.log10(float(str(time_slice)[::-1])))+2)\n",
    "    # creates a dictionary of data\n",
    "    hash_table = {}\n",
    "    hash_table['times'] = times\n",
    "    hash_table['fingerprint'] = Freqs_fingerprints[peaks]\n",
    "    # saves the data to a file\n",
    "    np.savez('./Fingerprints/{}.npz'.format(file_name[:-4]), **hash_table)\n",
    "    return hash_table\n",
    "\n",
    "def create_fingerprint_sample(fingerprints, rate, time_slice: float,octave_factor = 1):\n",
    "    '''Function to generate a fingerprint of a sample that can then be compared\n",
    "        to the database '''\n",
    "    Fourier_fingerprints = fft.rfft(fingerprints)\n",
    "    Freqs_fingerprints = fft.rfftfreq(fingerprints.shape[-1], 1/rate)\n",
    "    peaks, times = hashed_freqs_nonuniform(Freqs_fingerprints,Fourier_fingerprints,time_slice,octave_factor)\n",
    "    times = np.round(times, int(np.log10(float(str(time_slice)[::-1])))+2)\n",
    "    return times, Freqs_fingerprints[peaks]\n",
    "\n",
    "def create_fingerprint_sample_ARRAY(fingerprints, rate, time_slice: float,octave_factor = 1):\n",
    "    '''Function to generate a fingerprint of a sample that can then be compared\n",
    "        to the database '''\n",
    "    Fourier_fingerprints = fft.rfft(fingerprints)\n",
    "    Freqs_fingerprints = fft.rfftfreq(fingerprints.shape[-1], 1/rate)\n",
    "    peaks, times = hashed_freqs_ARRAY(Freqs_fingerprints,Fourier_fingerprints,time_slice,octave_factor)\n",
    "    times = np.round(times, int(np.log10(float(str(time_slice)[::-1])))+2)\n",
    "    return times, peaks\n",
    "\n",
    "@nb.njit('Tuple((f8[:,:,:],f8[:,:,:]))(f8[:],f8[:,:],f8[:,:],f8[:])', parallel = True)\n",
    "def match_fingerprints(times_database, fingerprint_database, fingerprint_sample, times_sample):\n",
    "    ''' Function to find the time difference and frequency differences between the sample of a song and a song in the database'''\n",
    "    result_fingerprints = np.zeros((fingerprint_database.shape[0],fingerprint_sample.shape[0] , fingerprint_sample.shape[1]), dtype = np.float64)\n",
    "    result_times = np.zeros((times_database.size, times_sample.size, fingerprint_database.shape[-1]), dtype = np.float64)\n",
    "    # goes through the database time slices\n",
    "    for i in nb.prange(fingerprint_database.shape[0]):\n",
    "        # then the sample time slices of data\n",
    "        for j in nb.prange(fingerprint_sample.shape[0]):\n",
    "            # calculates the time difference between the values\n",
    "            temp = times_database[i] - times_sample[j]\n",
    "            # then iterates through the frequency axis \n",
    "            for k in nb.prange(fingerprint_database.shape[1]):\n",
    "                # result_times puts the same time for each frequency along the same timeslice\n",
    "                result_times[i,j,k] = temp\n",
    "                # result_fingerprint holds the difference between the Fourier peaks in the smaple and the database song\n",
    "                result_fingerprints[i,j,k] = fingerprint_database[i,k] - fingerprint_sample[j,k]\n",
    "    return result_fingerprints, result_times\n",
    "\n",
    "''' The functions below are for calculating noise data to generate noise on a sample digitally'''\n",
    "def P_to_DB(sig_avg_power):\n",
    "    return 10*np.log10(sig_avg_power)\n",
    "def Noise_Data(target_SNR, signal_avg_DB):\n",
    "    noise_avg_DB = signal_avg_DB - target_SNR\n",
    "    noise_avg_watts = np.power(10. , noise_avg_DB/10)\n",
    "    return noise_avg_DB, noise_avg_watts\n",
    "def generate_noise(mean_noise, noise_avg_watts, data_length):\n",
    "    return np.random.normal(mean_noise, np.sqrt(noise_avg_watts), data_length)\n",
    "####################\n",
    "# White Noise addition\n",
    "def gen_white_noise(target_SNR, data):\n",
    "    '''given a target SNR an array of white noise is generated and then summed with the data'''\n",
    "    target_SNR_DB = 10*np.log10(target_SNR)\n",
    "    signal_average_power = np.average(data**2)\n",
    "    sig_avg_DB = P_to_DB(signal_average_power)\n",
    "    noise_avg_DB, noise_avg_power = Noise_Data(target_SNR_DB, sig_avg_DB)\n",
    "    print('sig power',signal_average_power,'DB',sig_avg_DB,'\\n noise DB',noise_avg_DB, 'power',noise_avg_power,'\\n ratio', signal_average_power/noise_avg_power)\n",
    "    white_noise = generate_noise(0, noise_avg_power,data.size)\n",
    "    noisy_data = np.int32(data+white_noise)\n",
    "    return noisy_data\n",
    "################\n",
    "\n",
    "################\n",
    "# background noise addition\n",
    "def gen_background_noise(data, record_duration, target_SNR):\n",
    "    background_sounds = os.listdir('../BackgroundNoise/')\n",
    "    random_sample = np.random.randint(len(background_sounds))\n",
    "    background_rate, background_data = wavfile.read('../BackgroundNoise/{}'.format(background_sounds[random_sample]))\n",
    "    # print(background_sounds[random_sample])\n",
    "    background_data = np.sum(background_data,axis = -1, dtype = np.int32)\n",
    "    background_data = background_data * np.sqrt(np.average(np.int32(data)**2)/np.average(background_data**2))*(1/np.sqrt(target_SNR))\n",
    "    # print('background noise data', background_rate, background_data.shape)\n",
    "    background_start = np.random.randint(background_data.size-int(background_rate*record_duration))\n",
    "    # take a slice of the data from the song\n",
    "    random_background_sample = background_data[background_start:background_start+int(background_rate*record_duration)]\n",
    "    sample_plus_background = np.int32(data+random_background_sample)\n",
    "    return sample_plus_background, background_rate, background_sounds[random_sample]\n",
    "\n",
    "def gen_background_noise_ARRAY(data, record_duration, target_SNR, tests, random_sample):\n",
    "    background_sounds = os.listdir('../BackgroundNoise/')\n",
    "    # random_sample = np.random.randint(len(background_sounds))\n",
    "    background_rate, background_data = wavfile.read('../BackgroundNoise/{}'.format(background_sounds[random_sample]))\n",
    "    # print(background_sounds[random_sample])\n",
    "    background_data = np.sum(background_data,axis = -1, dtype = np.int64)\n",
    "    background_data = background_data * np.sqrt(np.average(np.int64(data)**2)/np.average(background_data**2))*(1/np.sqrt(target_SNR))\n",
    "    # take a slice of the data from the song\n",
    "    result = Chunking_Multisample(background_data,int(background_rate*record_duration), tests)\n",
    "    sample_plus_background = np.int64(data+result)\n",
    "    return sample_plus_background, background_rate, background_sounds[random_sample]\n",
    "\n",
    "\n",
    "def run_match(fingerprint_sample, times_sample):\n",
    "    '''runs the match finding and outputs the results'''\n",
    "    database = os.listdir('../Fingerprints/')\n",
    "    result = {}\n",
    "    # go through each entry in the database\n",
    "    for entry in database:\n",
    "        # load the data\n",
    "        with np.load('../Fingerprints/{}'.format(entry)) as data:\n",
    "            fingerprints = data['fingerprint']\n",
    "            times = data['times']\n",
    "            freq_range = 1. # the chosen difference in frequency values permitted\n",
    "            # creates the arrays of frequency differences and time_differences\n",
    "            freq_diff, time_diff = match_fingerprints(times, fingerprints, fingerprint_sample, times_sample)\n",
    "            # finds where the frequency differences are within the range of values\n",
    "            indexes = np.where(np.abs(freq_diff) < freq_range)\n",
    "            # reduces the frequencies into this range of close frequencies\n",
    "            reduced_freqs, reduced_times = freq_diff[indexes], time_diff[indexes]\n",
    "            # creates a histogram of the times where the frequencies were within the range\n",
    "            hist, hist_bins = np.histogram(reduced_times,  bins = 250)\n",
    "            # finds the maximum value of each histogram and the difference of the max value from the average\n",
    "            result[entry] = np.max(hist)-np.average(hist)\n",
    "    return result, hist, hist_bins, freq_diff, times, times_sample\n",
    "\n",
    "@nb.njit('f8[:](f8[:], i4)')\n",
    "def get_bin_edges(arr, bins):\n",
    "    bin_edges = np.zeros((bins+1), dtype = np.float64)\n",
    "    arr_min = arr.min()\n",
    "    arr_max = arr.max()\n",
    "    delta = (arr_max - arr_min)/bins\n",
    "    for i in range(bin_edges.shape[0]):\n",
    "        bin_edges[i] = arr_min + i * delta\n",
    "    bin_edges[-1] = arr_max  # Avoid roundoff error on last point\n",
    "    return bin_edges\n",
    "\n",
    "@nb.njit('Tuple((i8[:],f8[:]))(f8[:], i4)', parallel = True)\n",
    "def nb_hist(arr, bins):\n",
    "    hist = np.zeros((bins), dtype = np.int64)\n",
    "    bin_edges = get_bin_edges(arr, bins)\n",
    "    arr_min = bin_edges[0]\n",
    "    arr_max = bin_edges[-1]\n",
    "    # print('minmax', arr_min, arr_max)\n",
    "    arr = arr.flatten()\n",
    "    rnge = arr_max - arr_min\n",
    "    for val in nb.prange(arr.size):\n",
    "        if arr[val] == arr_max:\n",
    "            bin_num = bins-1\n",
    "        else:\n",
    "            bin_num = np.int64(bins * (arr[val] - arr_min) //rnge)\n",
    "        if bin_num < 0 or bin_num >= bins:\n",
    "            pass\n",
    "        else:\n",
    "            hist[bin_num] += 1\n",
    "    return hist, bin_edges\n",
    "@nb.njit('Tuple((f8[:,:],f8[:,:]))(f8[:],f8[:,:],f8[:,:],f8[:])', parallel = True)\n",
    "def match_fingerprints_new_version(times_database, fingerprint_database, fingerprint_sample, times_sample):\n",
    "    ''' Function to find the time difference and frequency differences between the sample of a song and a song in the database'''\n",
    "    result_fingerprints = np.zeros((fingerprint_database.shape[0],fingerprint_sample.shape[0]), dtype = np.float64)\n",
    "    result_times = np.zeros((times_database.size, times_sample.size), dtype = np.float64)\n",
    "    # goes through the database time slices\n",
    "    for i in nb.prange(fingerprint_database.shape[0]):\n",
    "        # then the sample time slices of data\n",
    "        for j in range(fingerprint_sample.shape[0]):\n",
    "            # calculates the time difference between the values\n",
    "            result_times[i,j] = times_database[i] - times_sample[j]\n",
    "            # then iterates through the frequency axis\n",
    "            cum_sum = 0\n",
    "            for k in range(fingerprint_database.shape[1]):\n",
    "                #  holds the difference between the Fourier peaks in the smaple and the database song\n",
    "                cum_sum += abs(fingerprint_database[i,k] - fingerprint_sample[j,k])\n",
    "                # /(fingerprint_database[i,k]**2+fingerprint_sample[j,k]**2)**0.5\n",
    "            result_fingerprints[i,j] = cum_sum/fingerprint_database.shape[1]\n",
    "    return result_fingerprints, result_times\n",
    "@nb.njit('f8[:](f8[:],f8[:,:],f8[:,:,:],f8[:,:], i4)', parallel = True)\n",
    "def match_arrays(song_times, song_fingerprints,mult_fingerprints, mult_time_samples, bins):\n",
    "    freq_range = 1.\n",
    "    similarities = np.zeros(mult_fingerprints.shape[0], dtype = np.float64)\n",
    "    for m in nb.prange(mult_fingerprints.shape[0]):\n",
    "        freq_diff_sum = np.zeros((song_fingerprints.shape[0],mult_fingerprints[m].shape[0]), dtype = np.float64)\n",
    "        time_diff = np.zeros((song_times.size, mult_time_samples[m].size), dtype = np.float64)\n",
    "        # goes through the database time slices\n",
    "        for i in nb.prange(song_fingerprints.shape[0]):\n",
    "            # then the sample time slices of data\n",
    "            for j in nb.prange(mult_fingerprints[m].shape[0]):\n",
    "                # calculates the time difference between the values\n",
    "                time_diff[i,j] = song_times[i] - mult_time_samples[m][j]\n",
    "                # then iterates through the frequency axis\n",
    "                cum_sum = 0\n",
    "                for k in range(song_fingerprints.shape[1]):\n",
    "                    #  holds the difference between the Fourier peaks in the smaple and the database song\n",
    "                    cum_sum += abs(song_fingerprints[i,k] - mult_fingerprints[m][j,k])\n",
    "                freq_diff_sum[i,j] = cum_sum\n",
    "        \n",
    "        # freq_diff_sum, time_diff = match_fingerprints_new_version(song_times, song_fingerprints, mult_fingerprints[i], mult_time_samples[i])\n",
    "        reduced_indexes = np.where(freq_diff_sum < 0.5*np.average(freq_diff_sum))\n",
    "        # print(freq_diff_sum.shape)\n",
    "        # print(reduced_indexes[-1].size)\n",
    "        reduced_times = np.zeros(reduced_indexes[-1].size, dtype = np.float64)\n",
    "        for n in nb.prange(reduced_indexes[-1].size):\n",
    "            reduced_times[n] = time_diff[reduced_indexes[0][n],reduced_indexes[1][n]]\n",
    "        hist, hist_bins = nb_hist(reduced_times, bins)\n",
    "        similarities[m] = np.max(hist) - np.average(hist)\n",
    "        # - np.average(hist)\n",
    "    return similarities\n",
    "\n",
    "\n",
    "def run_match_ARRAY(fingerprint_sample, times_sample, database = None):\n",
    "    if not database == None:\n",
    "        pass\n",
    "    else:\n",
    "        '''runs the match finding and outputs the results'''\n",
    "        database = os.listdir('../Fingerprints/')\n",
    "        result = {}\n",
    "        # go through each entry in the database\n",
    "        for entry in database:\n",
    "            # load the data\n",
    "            with np.load('../Fingerprints/{}'.format(entry)) as data:\n",
    "                fingerprints = data['fingerprint']\n",
    "                times = data['times']\n",
    "                # print(fingerprint_sample.shape)\n",
    "                similarity  = match_arrays(times, fingerprints, fingerprint_sample, times_sample, bins = 250)\n",
    "                result[entry] = similarity\n",
    "        return result\n",
    "\n",
    "@nb.njit('f8(i4[:], i4[:])')\n",
    "def test_results(true_song_indexes,  obtained_song_indexes):\n",
    "    accuracy = 0\n",
    "    for i in range(true_song_indexes.size):\n",
    "        if obtained_song_indexes[i] == true_song_indexes[i]:\n",
    "            accuracy += 1\n",
    "    return accuracy / true_song_indexes.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People Talking Sound Effect.wav\n"
     ]
    }
   ],
   "source": [
    "''' This is a theoretical tester to look for similarity'''\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "def run_sim(target_SNR, time_slice):\n",
    "    entries = os.listdir('../Music/')\n",
    "    amplitude = 0.2 # reduce the amplitude of the samples to reduce clipping\n",
    "    record_duration = 20 # how long the sample should be\n",
    "    # test_slice = int(np.floor(record_duration/time_slice))\n",
    "    # slices = int(np.floor(record_duration/time_slice))\n",
    "    # choose a random song\n",
    "    song = entries[np.random.randint(len(entries))]\n",
    "    print(song)\n",
    "    # access the song data\n",
    "    rate, data = wavfile.read('../Music/{}'.format(song))\n",
    "    # convert to mono and int32 so that squaring the data doesn't overflow the max number allowed\n",
    "    data = np.sum(data,axis = -1, dtype = np.int32)*amplitude\n",
    "    # choose a random place in the song\n",
    "    start = np.random.randint(data.size-int(rate*record_duration))\n",
    "    # take a slice of the data from the song\n",
    "    data = data[start:start+int(rate*record_duration)]\n",
    "    play_data = np.int16(data)\n",
    "    data_sample, background_rate, sound = gen_background_noise(data, record_duration, target_SNR= target_SNR)\n",
    "    play_data_sample = np.int16(data_sample)\n",
    "    # chunk the sample\n",
    "    fingerprints = Chunking_Sample(data_sample,int(time_slice*background_rate))\n",
    "    # create the fingerprint of the sample\n",
    "    times_sample, fingerprint_sample = create_fingerprint_sample(fingerprints,rate,time_slice,bins = bins)\n",
    "    # access the fingerprints database\n",
    "    result, hist, hist_bins, plt_freqs, orig_times, sample_times = run_match(fingerprint_sample, times_sample)\n",
    "    # print(result)\n",
    "    # the result where there is maximal difference between the average and the peak is the song that is playing\n",
    "    # print('the song playing', str(max(result, key=result.get))[:-4])\n",
    "    # print(song[:-4] == str(max(result, key=result.get))[:-4])\n",
    "    return play_data, play_data_sample, rate, song[:-4] == str(max(result, key=result.get))[:-4], hist, hist_bins, plt_freqs, orig_times, sample_times, str(max(result, key=result.get))[:-4]\n",
    "\n",
    "def gen_samples_array(target_SNR, tests, noise_sample, record_duration = 20, time_slice = 0.1, octave_factor = 1, entries_data = None):\n",
    "    if not entries_data == None:\n",
    "        database_times, database_fingerprints, rate, songs = entries_data\n",
    "        amplitude = 0.2 # reduce the amplitude of the samples to reduce clipping\n",
    "        # test_slice = int(np.floor(record_duration/time_slice))\n",
    "        # slices = int(np.floor(record_duration/time_slice))\n",
    "        song_samples = tests//database_times.shape[0]\n",
    "        # print('song samples', song_samples)\n",
    "        song_indexes = np.arange(database_times.shape[0])\n",
    "        comparison_array = np.repeat(song_indexes, song_samples)\n",
    "        background_sounds = os.listdir('../BackgroundNoise/')\n",
    "        if noise_sample == None:\n",
    "            noise_sample = np.random.randint(len(background_sounds))\n",
    "        # print(background_sounds[noise_sample])\n",
    "        total_data_sample = np.zeros((int(song_samples*database_times.shape[0]),int(rate*record_duration)), dtype=np.int64)\n",
    "        \n",
    "        for j in range(database_times.shape[0]):\n",
    "            # choose a random song\n",
    "            song = songs[j]\n",
    "            # access the song data\n",
    "            data = database_fingerprints[j]\n",
    "            # convert to mono and int32 so that squaring the data doesn't overflow the max number allowed\n",
    "            data = np.int64(data)\n",
    "            data = np.sum(data,axis = -1, dtype = np.int64)*amplitude\n",
    "            result = Chunking_Multisample(data, int(rate*record_duration), song_samples)\n",
    "            play_data = np.int16(data)\n",
    "            result_passthrough = np.int64(result)\n",
    "            data_sample, background_rate, sound = gen_background_noise_ARRAY(result_passthrough, record_duration, target_SNR, song_samples, noise_sample)\n",
    "            total_data_sample[j*song_samples: (j+1)*song_samples] = data_sample.copy()\n",
    "        play_data_sample = np.int16(data_sample)\n",
    "        fingerprints = Chunking_Sample_ARRAY(total_data_sample,int(time_slice*background_rate))\n",
    "        times_sample, fingerprint_sample = create_fingerprint_sample_ARRAY(fingerprints,rate,time_slice,octave_factor = octave_factor)\n",
    "        return fingerprint_sample, times_sample, song_samples, comparison_array\n",
    "    else:\n",
    "        entries = os.listdir('../Music/')\n",
    "        amplitude = 0.2 # reduce the amplitude of the samples to reduce clipping\n",
    "        # test_slice = int(np.floor(record_duration/time_slice))\n",
    "        # slices = int(np.floor(record_duration/time_slice))\n",
    "        song_samples = tests//len(entries)\n",
    "        # print('song samples', song_samples)\n",
    "        song_indexes = np.arange(len(entries))\n",
    "        comparison_array = np.repeat(song_indexes, song_samples)\n",
    "        background_sounds = os.listdir('../BackgroundNoise/')\n",
    "        if noise_sample == None:\n",
    "            noise_sample = np.random.randint(len(background_sounds))\n",
    "        # print(background_sounds[noise_sample])\n",
    "        song = entries[0]\n",
    "        rate, _ = wavfile.read('../Music/{}'.format(song))\n",
    "        del _\n",
    "        total_data_sample = np.zeros((int(song_samples*len(entries)),int(rate*record_duration)), dtype=np.int64)\n",
    "        for j in range(len(entries)):\n",
    "            # choose a random song\n",
    "            song = entries[j]\n",
    "            # access the song data\n",
    "            rate, data = wavfile.read('../Music/{}'.format(song))\n",
    "            # convert to mono and int32 so that squaring the data doesn't overflow the max number allowed\n",
    "            data = np.int64(data)\n",
    "            data = np.sum(data,axis = -1, dtype = np.int64)*amplitude\n",
    "            result = Chunking_Multisample(data, int(rate*record_duration), song_samples)\n",
    "            del data\n",
    "            result_passthrough = np.int64(result)\n",
    "            data_sample, background_rate, sound = gen_background_noise_ARRAY(result_passthrough, record_duration, target_SNR, song_samples, noise_sample)\n",
    "            del result_passthrough\n",
    "            total_data_sample[j*song_samples: (j+1)*song_samples] = data_sample.copy()\n",
    "        del data_sample, result\n",
    "        fingerprints = Chunking_Sample_ARRAY(total_data_sample,int(time_slice*background_rate))\n",
    "        del total_data_sample\n",
    "        times_sample, fingerprint_sample = create_fingerprint_sample_ARRAY(fingerprints,rate,time_slice,octave_factor = octave_factor)\n",
    "        del fingerprints\n",
    "        return fingerprint_sample, times_sample, song_samples, comparison_array\n",
    "\n",
    "def run_sim_array(tests, choice = True, optional_data = None, noise_sample = None,target_SNR = None, entries_data = None):\n",
    "    if not entries_data == None:\n",
    "        pass\n",
    "    else:\n",
    "        entries = os.listdir('../Music/')\n",
    "        if choice == True:\n",
    "            fingerprint_sample, times_sample, song_samples, comparison_array = gen_samples_array(target_SNR, tests, noise_sample)\n",
    "        else:\n",
    "            fingerprint_sample, times_sample, song_samples, comparison_array = optional_data\n",
    "        \n",
    "        \n",
    "        result = run_match_ARRAY(fingerprint_sample, times_sample)\n",
    "        template = np.zeros((len(entries), int(len(entries)*song_samples)))\n",
    "        for index, val in enumerate(result.keys()):\n",
    "            template[index] = result[val]\n",
    "        maxes = np.max(template, axis = 0)\n",
    "        indexes_max = np.zeros(maxes.size)\n",
    "        for i in range(maxes.size):\n",
    "            if np.where(template[:,i] == maxes[i])[0].size > 1:\n",
    "                indexes_max[i] = np.where(template[:,i] == maxes[i])[0][0]\n",
    "            else:\n",
    "                indexes_max[i] = np.where(template[:,i] == maxes[i])[0]\n",
    "        comparison_array = np.int32(comparison_array)\n",
    "        accuracy = test_results(comparison_array, np.int32(indexes_max))\n",
    "        return accuracy\n",
    "\n",
    "\n",
    "ind  = 4\n",
    "background_sounds = os.listdir('../BackgroundNoise/')\n",
    "print(background_sounds[ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data gen 2.0798782000001665\n",
      "data manipulation 0.30941079999865906\n",
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "tests = 20\n",
    "SNRs = np.logspace(-4, 1.5, 50, endpoint = True)\n",
    "accuracies = []\n",
    "ind  = 4\n",
    "entries = os.listdir('../Music/') # access the music wav database\n",
    "octave_factor = 2\n",
    "record_duration = 20\n",
    "time_slice  = 0.085\n",
    "for entry in entries:\n",
    "    hashes = create_fingerprint_song(entry, time_slice, octave_factor=octave_factor)\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "fingerprint_sample, times_sample, song_samples, comparison_array = gen_samples_array(100, tests, ind, record_duration=record_duration, time_slice=time_slice, octave_factor=octave_factor)\n",
    "print('data gen', time.perf_counter()-t0)\n",
    "t0 = time.perf_counter()\n",
    "final_accuracy = run_sim_array(tests, False, (fingerprint_sample, times_sample, song_samples, comparison_array))\n",
    "print('data manipulation',time.perf_counter() - t0)\n",
    "print(final_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0.004482269287109375, 0.013446807861328125, 0.031375885009765625, 0.06723403930664062, 0.13895034790039062, 0.2823829650878906, 0.5692481994628906, 1.1429786682128906, 2.2904396057128906, 4.585361480712891, 9.17520523071289, 18.35489273071289, 36.71426773071289, 73.43301773071289, 146.8705177307129, 293.7455177307129, 587.4955177307129, 1174.995517730713, 2349.995517730713, 4699.995517730713]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "bin_ratio = 2\n",
    "rng = 4700\n",
    "bins  = 20\n",
    "bin_size = rng/(bin_ratio**bins)\n",
    "\n",
    "bin_boundaries = [0]\n",
    "for i in range(bins):\n",
    "    bin_boundaries.append(bin_boundaries[-1]+ bin_size)\n",
    "    bin_size *= bin_ratio\n",
    "\n",
    "\n",
    "print(bin_boundaries)\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sounddevice as SD\n",
    "from scipy.io import wavfile\n",
    "import scipy.fft as fft\n",
    "import matplotlib.pyplot as plt\n",
    "import numba as nb\n",
    "import os\n",
    "import functools\n",
    "import time\n",
    "import math\n",
    "@nb.njit(['f8[:](i4[:], i4)', 'f8(i4, i4)'])\n",
    "def note_frequencies(n, f0):\n",
    "    ''' This simply returns the frequencies of the notes along the equal temperament scale'''\n",
    "    ''' f0 -> fundamental frequency / Hz\n",
    "        n -> number of halfsteps from note'''\n",
    "    return f0 * np.power(2,n/12)\n",
    "\n",
    "@nb.njit('Tuple((i4[:,:],f8[:]))(f8[:], c16[:,:],f8,i4)', parallel = True)\n",
    "def hashed_freqs_nonuniform(freqs, fourier, time_slices, octave_factor):\n",
    "    ''' Function to generate a set of times and the peaks of the fourier transform \n",
    "    for a sample of music'''\n",
    "    semitone_steps = int(12/octave_factor)\n",
    "    base_range = 5\n",
    "    range_lower = int(base_range*octave_factor)\n",
    "    range_upper = int(base_range*octave_factor) - (octave_factor-1)\n",
    "    semitones = np.array([i*semitone_steps for i in range(-range_lower,range_upper,1)], dtype=np.int32)\n",
    "    bin_edges = note_frequencies(semitones, 440)\n",
    "\n",
    "    peaks = np.empty((fourier.shape[0],bins), dtype = np.int32)\n",
    "    times = np.empty(fourier.shape[0])\n",
    "    # resolution gives the length of a section of each bin\n",
    "    for time in nb.prange(fourier.shape[0]):\n",
    "        # iterates through each time slice of music\n",
    "        for bin in nb.prange(len(bin_edges)-1):\n",
    "            # works through each bin range to find the freq upper and lower limits\n",
    "            upper_lim = bin_edges[bin]\n",
    "            lower_lim = bin_edges[bin+1]\n",
    "            # finds the indices of the freqs where this occurs\n",
    "            indices = np.where((freqs <= upper_lim) & (freqs > lower_lim))[0]\n",
    "            # finds the peak in this range\n",
    "            peak = np.where(np.abs(fourier[time][indices]) == np.max(np.abs(fourier[time][indices])))[0][0]\n",
    "            # appends the position of the peak within the overall data set to an array\n",
    "            peaks[time][bin] = np.int32(peak)\n",
    "        # calculates the time where this time slice occurred\n",
    "        times[time] = time*time_slices\n",
    "    return peaks, times\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27.5, 110.0, 123.47082531403103, 138.59131548843604, 155.56349186104043, 174.61411571650194, 195.99771799087463, 220.0, 246.94165062806206, 277.1826309768721, 311.12698372208087, 349.2282314330039, 391.99543598174927, 440.0, 493.8833012561241, 554.3652619537442, 622.2539674441618, 698.4564628660078, 783.9908719634985, 880.0, 987.7666025122483, 1108.7305239074883, 1244.5079348883237, 1396.9129257320155, 1567.981743926997, 1760.0, 1975.533205024496, 2217.4610478149766, 2489.0158697766474, 2793.825851464031, 3135.9634878539946, 3520.0, 3951.066410048992, 4434.922095629953, 4978.031739553295, 5587.651702928062, 6271.926975707989, 7040.0]\n"
     ]
    }
   ],
   "source": [
    "octave_factor = 6\n",
    "semitone_steps = int(12/octave_factor)\n",
    "range_lower = int(4*octave_factor)\n",
    "range_upper = int(5*octave_factor) - (octave_factor-1)\n",
    "semitones = np.array([i*semitone_steps for i in range(-range_lower,range_upper,1)], dtype=np.int32)\n",
    "bin_edges = note_frequencies(semitones, 440)\n",
    "\n",
    "@nb.njit()\n",
    "def remove_bins(bin_edges):\n",
    "    bin_edges_reduced = [bin_edges[0]]\n",
    "    for i in range(len(bin_edges)-1):\n",
    "        if bin_edges[i+1] - bin_edges[i] > 12:\n",
    "            bin_edges_reduced.append(bin_edges[i+1])\n",
    "    return bin_edges_reduced\n",
    "\n",
    "print(remove_bins(bin_edges))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
